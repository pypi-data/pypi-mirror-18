/l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab
Reading vocabulary from /l/senarvi/theanolm-recipes/penn-treebank/nnlm.vocab.
Number of words in vocabulary: 10001
Number of word classes: 10001
2016-11-22 20:02:16,493 train: TRAINING OPTIONS
2016-11-22 20:02:16,493 train: patience: 0
2016-11-22 20:02:16,493 train: min_epochs: 1
2016-11-22 20:02:16,493 train: sequence_length: 25
2016-11-22 20:02:16,493 train: batch_size: 32
2016-11-22 20:02:16,493 train: max_annealing_count: 0
2016-11-22 20:02:16,493 train: max_epochs: 15
2016-11-22 20:02:16,493 train: validation_frequency: 1
2016-11-22 20:02:16,493 train: stopping_criterion: no-improvement
2016-11-22 20:02:16,493 train: OPTIMIZATION OPTIONS
2016-11-22 20:02:16,493 train: sqr_gradient_decay_rate: 0.999
2016-11-22 20:02:16,493 train: unk_penalty: None
2016-11-22 20:02:16,493 train: learning_rate: 10.0
2016-11-22 20:02:16,494 train: ignore_unk: False
2016-11-22 20:02:16,494 train: momentum: 0.9
2016-11-22 20:02:16,494 train: gradient_decay_rate: 0.9
2016-11-22 20:02:16,494 train: max_gradient_norm: 5.0
2016-11-22 20:02:16,494 train: epsilon: 1e-06
2016-11-22 20:02:16,494 train: num_noise_samples: 1
2016-11-22 20:02:16,494 train: cost_function: cross-entropy
2016-11-22 20:02:16,494 train: method: sgd
2016-11-22 20:02:16,494 train: weights: [ 1.]
Creating trainer.
Computing unigram probabilities and the number of mini-batches in training data.
2016-11-22 20:02:17,654 __init__: One epoch of training data contains 1778 mini-batch updates.
2016-11-22 20:02:17,655 __init__: Class unigram probabilities are in the range [0.00000103, 0.05232915].
2016-11-22 20:02:17,655 __init__: Finding sentence start positions in /teamwork/t40511_asr/c/penn-treebank-project/ptb.train.txt.
2016-11-22 20:02:17,717 _reset: Generating a random order of input lines.
Building neural network.
2016-11-22 20:02:17,725 __init__: Creating layers.
2016-11-22 20:02:17,725 __init__: - NetworkInput name=word_input inputs=[] size=10001
2016-11-22 20:02:17,725 __init__: - ProjectionLayer name=projection_layer inputs=[word_input] size=100
2016-11-22 20:02:17,765 __init__: - LSTMLayer name=hidden_layer inputs=[projection_layer] size=256
2016-11-22 20:02:17,892 __init__: - HSoftmaxLayer name=output_layer inputs=[hidden_layer] size=10001
2016-11-22 20:02:17,892 __init__:   level1_size=101 level2_size=100
2016-11-22 20:02:18,009 __init__: Initializing parameters.
2016-11-22 20:02:18,009 __init__: - layers/projection_layer/W size=1000100 type=float32
2016-11-22 20:02:18,010 __init__: - layers/hidden_layer/layer_input/W size=102400 type=float32
2016-11-22 20:02:18,010 __init__: - layers/hidden_layer/step_input/W size=262144 type=float32
2016-11-22 20:02:18,010 __init__: - layers/hidden_layer/layer_input/b size=1024 type=float32
2016-11-22 20:02:18,010 __init__: - layers/output_layer/input/W size=25856 type=float32
2016-11-22 20:02:18,010 __init__: - layers/output_layer/input/b size=101 type=float32
2016-11-22 20:02:18,010 __init__: - layers/output_layer/level1/W size=2585600 type=float32
2016-11-22 20:02:18,010 __init__: - layers/output_layer/level1/b size=10100 type=float32
2016-11-22 20:02:18,010 __init__: Total number of parameters: 3987325
Compiling optimization function.
Building text scorer for cross-validation.
Validation text: /teamwork/t40511_asr/c/penn-treebank-project/ptb.valid.txt
Training neural network.
2016-11-22 20:02:44,955 _log_update: [200] (11.2 %) of epoch 1 -- lr = 1e+01, cost = 6.71, duration = 7.4 ms
2016-11-22 20:03:00,030 _log_update: [400] (22.5 %) of epoch 1 -- lr = 1e+01, cost = 6.73, duration = 7.3 ms
2016-11-22 20:03:15,213 _log_update: [600] (33.7 %) of epoch 1 -- lr = 1e+01, cost = 6.11, duration = 7.8 ms
2016-11-22 20:03:31,275 _log_update: [800] (45.0 %) of epoch 1 -- lr = 1e+01, cost = 6.07, duration = 7.4 ms
2016-11-22 20:03:46,442 _log_update: [1000] (56.2 %) of epoch 1 -- lr = 1e+01, cost = 6.15, duration = 7.3 ms
2016-11-22 20:04:01,642 _log_update: [1200] (67.5 %) of epoch 1 -- lr = 1e+01, cost = 5.85, duration = 9.2 ms
2016-11-22 20:04:16,786 _log_update: [1400] (78.7 %) of epoch 1 -- lr = 1e+01, cost = 5.96, duration = 7.3 ms
2016-11-22 20:04:32,075 _log_update: [1600] (90.0 %) of epoch 1 -- lr = 1e+01, cost = 5.53, duration = 7.4 ms
2016-11-22 20:04:47,832 _validate: [1772] First validation sample, perplexity 264.34.
2016-11-22 20:04:55,439 _validate: [1775] Center of validation, perplexity 262.72.
2016-11-22 20:05:03,375 _validate: [1778] Last validation sample, perplexity 258.73.
2016-11-22 20:05:03,398 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:05:03,398 _log_validation: [1778] Validation set cost history: [259.5]
2016-11-22 20:05:03,399 _reset: Generating a random order of input lines.
Finished training epoch 1 in 0 hours 2.6 minutes. Best validation perplexity 259.54.
2016-11-22 20:05:05,110 _log_update: [22] (1.2 %) of epoch 2 -- lr = 1e+01, cost = 5.53, duration = 7.6 ms
2016-11-22 20:05:20,546 _log_update: [222] (12.5 %) of epoch 2 -- lr = 1e+01, cost = 4.84, duration = 7.6 ms
2016-11-22 20:05:35,805 _log_update: [422] (23.7 %) of epoch 2 -- lr = 1e+01, cost = 5.62, duration = 7.4 ms
2016-11-22 20:05:51,455 _log_update: [622] (35.0 %) of epoch 2 -- lr = 1e+01, cost = 5.65, duration = 7.7 ms
2016-11-22 20:06:06,615 _log_update: [822] (46.2 %) of epoch 2 -- lr = 1e+01, cost = 5.60, duration = 7.6 ms
2016-11-22 20:06:22,005 _log_update: [1022] (57.5 %) of epoch 2 -- lr = 1e+01, cost = 5.59, duration = 7.5 ms
2016-11-22 20:06:37,657 _log_update: [1222] (68.7 %) of epoch 2 -- lr = 1e+01, cost = 5.19, duration = 7.3 ms
2016-11-22 20:06:53,567 _log_update: [1422] (80.0 %) of epoch 2 -- lr = 1e+01, cost = 5.40, duration = 10.5 ms
2016-11-22 20:07:09,020 _log_update: [1622] (91.2 %) of epoch 2 -- lr = 1e+01, cost = 5.45, duration = 7.5 ms
2016-11-22 20:07:23,154 _validate: [1772] First validation sample, perplexity 189.30.
2016-11-22 20:07:30,642 _validate: [1775] Center of validation, perplexity 189.57.
2016-11-22 20:07:38,782 _validate: [1778] Last validation sample, perplexity 188.75.
2016-11-22 20:07:38,807 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:07:38,807 _log_validation: [1778] Validation set cost history: 259.5 [189.1]
2016-11-22 20:07:38,808 _reset: Generating a random order of input lines.
Finished training epoch 2 in 0 hours 2.6 minutes. Best validation perplexity 189.10.
2016-11-22 20:07:42,213 _log_update: [44] (2.5 %) of epoch 3 -- lr = 1e+01, cost = 5.01, duration = 7.4 ms
2016-11-22 20:07:57,740 _log_update: [244] (13.7 %) of epoch 3 -- lr = 1e+01, cost = 5.32, duration = 7.6 ms
2016-11-22 20:08:12,915 _log_update: [444] (25.0 %) of epoch 3 -- lr = 1e+01, cost = 5.07, duration = 9.5 ms
2016-11-22 20:08:28,450 _log_update: [644] (36.2 %) of epoch 3 -- lr = 1e+01, cost = 5.22, duration = 7.4 ms
2016-11-22 20:08:43,710 _log_update: [844] (47.5 %) of epoch 3 -- lr = 1e+01, cost = 5.38, duration = 7.5 ms
2016-11-22 20:08:59,142 _log_update: [1044] (58.7 %) of epoch 3 -- lr = 1e+01, cost = 5.28, duration = 8.2 ms
2016-11-22 20:09:15,314 _log_update: [1244] (70.0 %) of epoch 3 -- lr = 1e+01, cost = 5.04, duration = 7.6 ms
2016-11-22 20:09:31,173 _log_update: [1444] (81.2 %) of epoch 3 -- lr = 1e+01, cost = 5.35, duration = 7.8 ms
2016-11-22 20:09:47,038 _log_update: [1644] (92.5 %) of epoch 3 -- lr = 1e+01, cost = 4.76, duration = 7.9 ms
2016-11-22 20:10:00,085 _validate: [1772] First validation sample, perplexity 164.43.
2016-11-22 20:10:07,650 _validate: [1775] Center of validation, perplexity 165.70.
2016-11-22 20:10:15,242 _validate: [1778] Last validation sample, perplexity 163.36.
2016-11-22 20:10:15,259 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:10:15,259 _log_validation: [1778] Validation set cost history: 259.5 189.1 [163.4]
2016-11-22 20:10:15,260 _reset: Generating a random order of input lines.
Finished training epoch 3 in 0 hours 2.6 minutes. Best validation perplexity 163.36.
2016-11-22 20:10:20,329 _log_update: [66] (3.7 %) of epoch 4 -- lr = 1e+01, cost = 4.82, duration = 7.9 ms
2016-11-22 20:10:35,850 _log_update: [266] (15.0 %) of epoch 4 -- lr = 1e+01, cost = 4.96, duration = 7.3 ms
2016-11-22 20:10:51,519 _log_update: [466] (26.2 %) of epoch 4 -- lr = 1e+01, cost = 5.16, duration = 7.3 ms
2016-11-22 20:11:06,975 _log_update: [666] (37.5 %) of epoch 4 -- lr = 1e+01, cost = 5.18, duration = 7.5 ms
2016-11-22 20:11:22,301 _log_update: [866] (48.7 %) of epoch 4 -- lr = 1e+01, cost = 4.76, duration = 7.5 ms
2016-11-22 20:11:37,585 _log_update: [1066] (60.0 %) of epoch 4 -- lr = 1e+01, cost = 4.89, duration = 11.2 ms
2016-11-22 20:11:53,524 _log_update: [1266] (71.2 %) of epoch 4 -- lr = 1e+01, cost = 4.85, duration = 7.7 ms
2016-11-22 20:12:09,111 _log_update: [1466] (82.5 %) of epoch 4 -- lr = 1e+01, cost = 5.11, duration = 7.8 ms
2016-11-22 20:12:24,648 _log_update: [1666] (93.7 %) of epoch 4 -- lr = 1e+01, cost = 4.82, duration = 7.4 ms
2016-11-22 20:12:35,029 _validate: [1772] First validation sample, perplexity 149.72.
2016-11-22 20:12:42,697 _validate: [1775] Center of validation, perplexity 148.96.
2016-11-22 20:12:50,026 _validate: [1778] Last validation sample, perplexity 150.21.
2016-11-22 20:12:50,043 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:12:50,043 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 [149.1]
2016-11-22 20:12:50,044 _reset: Generating a random order of input lines.
Finished training epoch 4 in 0 hours 2.6 minutes. Best validation perplexity 149.07.
2016-11-22 20:12:56,739 _log_update: [88] (4.9 %) of epoch 5 -- lr = 1e+01, cost = 4.76, duration = 7.4 ms
2016-11-22 20:13:12,298 _log_update: [288] (16.2 %) of epoch 5 -- lr = 1e+01, cost = 5.02, duration = 7.4 ms
2016-11-22 20:13:27,790 _log_update: [488] (27.4 %) of epoch 5 -- lr = 1e+01, cost = 4.66, duration = 7.8 ms
2016-11-22 20:13:43,036 _log_update: [688] (38.7 %) of epoch 5 -- lr = 1e+01, cost = 4.78, duration = 7.3 ms
2016-11-22 20:13:58,151 _log_update: [888] (49.9 %) of epoch 5 -- lr = 1e+01, cost = 4.61, duration = 7.4 ms
2016-11-22 20:14:13,275 _log_update: [1088] (61.2 %) of epoch 5 -- lr = 1e+01, cost = 4.41, duration = 7.4 ms
2016-11-22 20:14:28,553 _log_update: [1288] (72.4 %) of epoch 5 -- lr = 1e+01, cost = 5.09, duration = 7.5 ms
2016-11-22 20:14:44,161 _log_update: [1488] (83.7 %) of epoch 5 -- lr = 1e+01, cost = 4.87, duration = 7.5 ms
2016-11-22 20:14:59,299 _log_update: [1688] (94.9 %) of epoch 5 -- lr = 1e+01, cost = 4.64, duration = 7.3 ms
2016-11-22 20:15:07,990 _validate: [1772] First validation sample, perplexity 142.24.
2016-11-22 20:15:15,253 _validate: [1775] Center of validation, perplexity 143.09.
2016-11-22 20:15:22,555 _validate: [1778] Last validation sample, perplexity 142.16.
2016-11-22 20:15:22,573 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:15:22,573 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 [142.2]
2016-11-22 20:15:22,573 _reset: Generating a random order of input lines.
Finished training epoch 5 in 0 hours 2.5 minutes. Best validation perplexity 142.24.
2016-11-22 20:15:31,053 _log_update: [110] (6.2 %) of epoch 6 -- lr = 1e+01, cost = 4.43, duration = 7.3 ms
2016-11-22 20:15:46,151 _log_update: [310] (17.4 %) of epoch 6 -- lr = 1e+01, cost = 4.45, duration = 7.3 ms
2016-11-22 20:16:01,354 _log_update: [510] (28.7 %) of epoch 6 -- lr = 1e+01, cost = 4.85, duration = 7.6 ms
2016-11-22 20:16:16,583 _log_update: [710] (39.9 %) of epoch 6 -- lr = 1e+01, cost = 4.60, duration = 7.4 ms
2016-11-22 20:16:32,249 _log_update: [910] (51.2 %) of epoch 6 -- lr = 1e+01, cost = 4.67, duration = 7.4 ms
2016-11-22 20:16:47,688 _log_update: [1110] (62.4 %) of epoch 6 -- lr = 1e+01, cost = 4.73, duration = 8.0 ms
2016-11-22 20:17:03,145 _log_update: [1310] (73.7 %) of epoch 6 -- lr = 1e+01, cost = 4.55, duration = 7.7 ms
2016-11-22 20:17:18,474 _log_update: [1510] (84.9 %) of epoch 6 -- lr = 1e+01, cost = 4.53, duration = 7.6 ms
2016-11-22 20:17:33,547 _log_update: [1710] (96.2 %) of epoch 6 -- lr = 1e+01, cost = 4.78, duration = 7.3 ms
2016-11-22 20:17:40,628 _validate: [1772] First validation sample, perplexity 138.45.
2016-11-22 20:17:48,084 _validate: [1775] Center of validation, perplexity 138.29.
2016-11-22 20:17:55,244 _validate: [1778] Last validation sample, perplexity 137.69.
2016-11-22 20:17:55,261 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:17:55,261 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 [138.3]
2016-11-22 20:17:55,261 _reset: Generating a random order of input lines.
Finished training epoch 6 in 0 hours 2.5 minutes. Best validation perplexity 138.29.
2016-11-22 20:18:05,211 _log_update: [132] (7.4 %) of epoch 7 -- lr = 1e+01, cost = 4.37, duration = 7.4 ms
2016-11-22 20:18:20,365 _log_update: [332] (18.7 %) of epoch 7 -- lr = 1e+01, cost = 4.84, duration = 7.3 ms
2016-11-22 20:18:35,181 _log_update: [532] (29.9 %) of epoch 7 -- lr = 1e+01, cost = 4.77, duration = 7.3 ms
2016-11-22 20:18:50,167 _log_update: [732] (41.2 %) of epoch 7 -- lr = 1e+01, cost = 4.44, duration = 7.6 ms
2016-11-22 20:19:06,276 _log_update: [932] (52.4 %) of epoch 7 -- lr = 1e+01, cost = 4.51, duration = 7.3 ms
2016-11-22 20:19:21,023 _log_update: [1132] (63.7 %) of epoch 7 -- lr = 1e+01, cost = 4.57, duration = 7.3 ms
2016-11-22 20:19:35,769 _log_update: [1332] (74.9 %) of epoch 7 -- lr = 1e+01, cost = 4.85, duration = 7.3 ms
2016-11-22 20:19:50,492 _log_update: [1532] (86.2 %) of epoch 7 -- lr = 1e+01, cost = 4.43, duration = 7.3 ms
2016-11-22 20:20:05,246 _log_update: [1732] (97.4 %) of epoch 7 -- lr = 1e+01, cost = 4.68, duration = 7.3 ms
2016-11-22 20:20:10,462 _validate: [1772] First validation sample, perplexity 136.59.
2016-11-22 20:20:17,441 _validate: [1775] Center of validation, perplexity 137.05.
2016-11-22 20:20:24,422 _validate: [1778] Last validation sample, perplexity 138.11.
2016-11-22 20:20:24,438 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:20:24,438 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 [137.1]
2016-11-22 20:20:24,438 _reset: Generating a random order of input lines.
Finished training epoch 7 in 0 hours 2.5 minutes. Best validation perplexity 137.05.
2016-11-22 20:20:35,787 _log_update: [154] (8.7 %) of epoch 8 -- lr = 1e+01, cost = 4.59, duration = 7.3 ms
2016-11-22 20:20:50,527 _log_update: [354] (19.9 %) of epoch 8 -- lr = 1e+01, cost = 4.20, duration = 7.3 ms
2016-11-22 20:21:05,281 _log_update: [554] (31.2 %) of epoch 8 -- lr = 1e+01, cost = 4.43, duration = 7.3 ms
2016-11-22 20:21:20,013 _log_update: [754] (42.4 %) of epoch 8 -- lr = 1e+01, cost = 4.53, duration = 7.3 ms
2016-11-22 20:21:34,744 _log_update: [954] (53.7 %) of epoch 8 -- lr = 1e+01, cost = 4.55, duration = 7.3 ms
2016-11-22 20:21:49,473 _log_update: [1154] (64.9 %) of epoch 8 -- lr = 1e+01, cost = 4.45, duration = 7.3 ms
2016-11-22 20:22:04,200 _log_update: [1354] (76.2 %) of epoch 8 -- lr = 1e+01, cost = 4.52, duration = 7.2 ms
2016-11-22 20:22:18,924 _log_update: [1554] (87.4 %) of epoch 8 -- lr = 1e+01, cost = 4.34, duration = 7.3 ms
2016-11-22 20:22:33,647 _log_update: [1754] (98.7 %) of epoch 8 -- lr = 1e+01, cost = 4.60, duration = 7.3 ms
2016-11-22 20:22:37,224 _validate: [1772] First validation sample, perplexity 140.69.
2016-11-22 20:22:44,199 _validate: [1775] Center of validation, perplexity 139.42.
2016-11-22 20:22:51,184 _validate: [1778] Last validation sample, perplexity 138.53.
2016-11-22 20:22:51,184 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 [137.1] 138.9
2016-11-22 20:22:51,185 set_state: layers/output_layer/input/b <- array(101,)
2016-11-22 20:22:51,185 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2016-11-22 20:22:51,188 set_state: layers/output_layer/level1/W <- array(101, 256, 100)
2016-11-22 20:22:51,190 set_state: layers/projection_layer/W <- array(10001, 100)
2016-11-22 20:22:51,190 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2016-11-22 20:22:51,191 set_state: layers/output_layer/level1/b <- array(101, 100)
2016-11-22 20:22:51,191 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2016-11-22 20:22:51,192 set_state: layers/output_layer/input/W <- array(256, 101)
2016-11-22 20:22:51,193 _reset_state: [1775] (99.83 %) of epoch 7
2016-11-22 20:22:51,193 _log_validation: [1775] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 [137.1]
2016-11-22 20:22:51,193 set_state: Restored iterator to line 42003 of 42068.
2016-11-22 20:22:51,194 set_state: layers/output_layer/level1/b_gradient <- array(101, 100)
2016-11-22 20:22:51,194 set_state: layers/output_layer/input/b_gradient <- array(101,)
2016-11-22 20:22:51,195 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2016-11-22 20:22:51,196 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2016-11-22 20:22:51,197 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2016-11-22 20:22:51,197 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2016-11-22 20:22:51,200 set_state: layers/output_layer/level1/W_gradient <- array(101, 256, 100)
2016-11-22 20:22:51,201 set_state: layers/output_layer/input/W_gradient <- array(256, 101)
Model performance stopped improving. Decreasing learning rate from 10.0 to 5.0 and resetting state to 100 % of epoch 7.
2016-11-22 20:22:51,201 _reset: Generating a random order of input lines.
Finished training epoch 7 in 0 hours 2.4 minutes. Best validation perplexity 137.05.
2016-11-22 20:23:04,169 _log_update: [176] (9.9 %) of epoch 8 -- lr = 5, cost = 4.31, duration = 7.3 ms
2016-11-22 20:23:18,892 _log_update: [376] (21.1 %) of epoch 8 -- lr = 5, cost = 4.55, duration = 7.3 ms
2016-11-22 20:23:33,608 _log_update: [576] (32.4 %) of epoch 8 -- lr = 5, cost = 3.85, duration = 7.3 ms
2016-11-22 20:23:48,331 _log_update: [776] (43.6 %) of epoch 8 -- lr = 5, cost = 4.51, duration = 7.3 ms
2016-11-22 20:24:03,053 _log_update: [976] (54.9 %) of epoch 8 -- lr = 5, cost = 4.01, duration = 7.3 ms
2016-11-22 20:24:17,777 _log_update: [1176] (66.1 %) of epoch 8 -- lr = 5, cost = 4.22, duration = 7.3 ms
2016-11-22 20:24:32,497 _log_update: [1376] (77.4 %) of epoch 8 -- lr = 5, cost = 4.69, duration = 7.3 ms
2016-11-22 20:24:47,224 _log_update: [1576] (88.6 %) of epoch 8 -- lr = 5, cost = 4.03, duration = 7.3 ms
2016-11-22 20:25:03,910 _validate: [1772] First validation sample, perplexity 132.72.
2016-11-22 20:25:10,891 _validate: [1775] Center of validation, perplexity 133.22.
2016-11-22 20:25:10,983 _log_update: [1776] (99.9 %) of epoch 8 -- lr = 5, cost = 4.49, duration = 7.4 ms
2016-11-22 20:25:17,882 _validate: [1778] Last validation sample, perplexity 133.58.
2016-11-22 20:25:17,898 _set_candidate_state: New candidate for optimal state saved to /l/senarvi/theanolm-recipes/penn-treebank/nnlm.h5.
2016-11-22 20:25:17,899 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 137.1 [132.8]
2016-11-22 20:25:17,899 _reset: Generating a random order of input lines.
Finished training epoch 8 in 0 hours 2.4 minutes. Best validation perplexity 132.79.
2016-11-22 20:25:32,484 _log_update: [198] (11.1 %) of epoch 9 -- lr = 5, cost = 3.92, duration = 7.3 ms
2016-11-22 20:25:47,223 _log_update: [398] (22.4 %) of epoch 9 -- lr = 5, cost = 4.20, duration = 7.3 ms
2016-11-22 20:26:02,030 _log_update: [598] (33.6 %) of epoch 9 -- lr = 5, cost = 4.34, duration = 7.5 ms
2016-11-22 20:26:17,263 _log_update: [798] (44.9 %) of epoch 9 -- lr = 5, cost = 4.32, duration = 7.5 ms
2016-11-22 20:26:32,476 _log_update: [998] (56.1 %) of epoch 9 -- lr = 5, cost = 4.32, duration = 7.5 ms
2016-11-22 20:26:47,688 _log_update: [1198] (67.4 %) of epoch 9 -- lr = 5, cost = 3.77, duration = 7.5 ms
2016-11-22 20:27:02,818 _log_update: [1398] (78.6 %) of epoch 9 -- lr = 5, cost = 4.41, duration = 7.3 ms
2016-11-22 20:27:17,555 _log_update: [1598] (89.9 %) of epoch 9 -- lr = 5, cost = 4.14, duration = 7.3 ms
2016-11-22 20:27:32,621 _validate: [1772] First validation sample, perplexity 134.82.
2016-11-22 20:27:39,597 _validate: [1775] Center of validation, perplexity 134.30.
2016-11-22 20:27:46,584 _validate: [1778] Last validation sample, perplexity 134.32.
2016-11-22 20:27:46,584 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 137.1 [132.8] 134.4
2016-11-22 20:27:46,585 set_state: layers/output_layer/input/b <- array(101,)
2016-11-22 20:27:46,585 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2016-11-22 20:27:46,588 set_state: layers/output_layer/level1/W <- array(101, 256, 100)
2016-11-22 20:27:46,590 set_state: layers/projection_layer/W <- array(10001, 100)
2016-11-22 20:27:46,590 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2016-11-22 20:27:46,590 set_state: layers/output_layer/level1/b <- array(101, 100)
2016-11-22 20:27:46,591 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2016-11-22 20:27:46,591 set_state: layers/output_layer/input/W <- array(256, 101)
2016-11-22 20:27:46,592 _reset_state: [1775] (99.83 %) of epoch 8
2016-11-22 20:27:46,593 _log_validation: [1775] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 137.1 [132.8]
2016-11-22 20:27:46,593 set_state: Restored iterator to line 42005 of 42068.
2016-11-22 20:27:46,593 set_state: layers/output_layer/level1/b_gradient <- array(101, 100)
2016-11-22 20:27:46,594 set_state: layers/output_layer/input/b_gradient <- array(101,)
2016-11-22 20:27:46,594 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2016-11-22 20:27:46,596 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2016-11-22 20:27:46,596 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2016-11-22 20:27:46,597 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2016-11-22 20:27:46,600 set_state: layers/output_layer/level1/W_gradient <- array(101, 256, 100)
2016-11-22 20:27:46,600 set_state: layers/output_layer/input/W_gradient <- array(256, 101)
Model performance stopped improving. Decreasing learning rate from 5.0 to 2.5 and resetting state to 100 % of epoch 8.
2016-11-22 20:27:46,601 _reset: Generating a random order of input lines.
Finished training epoch 8 in 0 hours 2.5 minutes. Best validation perplexity 132.79.
2016-11-22 20:27:48,081 _log_update: [20] (1.1 %) of epoch 9 -- lr = 2, cost = 4.00, duration = 7.3 ms
2016-11-22 20:28:03,029 _log_update: [220] (12.4 %) of epoch 9 -- lr = 2, cost = 3.90, duration = 7.5 ms
2016-11-22 20:28:17,959 _log_update: [420] (23.6 %) of epoch 9 -- lr = 2, cost = 4.05, duration = 7.3 ms
2016-11-22 20:28:32,679 _log_update: [620] (34.9 %) of epoch 9 -- lr = 2, cost = 4.19, duration = 7.3 ms
2016-11-22 20:28:47,396 _log_update: [820] (46.1 %) of epoch 9 -- lr = 2, cost = 4.02, duration = 7.3 ms
2016-11-22 20:29:02,121 _log_update: [1020] (57.4 %) of epoch 9 -- lr = 2, cost = 4.43, duration = 7.3 ms
2016-11-22 20:29:16,848 _log_update: [1220] (68.6 %) of epoch 9 -- lr = 2, cost = 4.18, duration = 7.3 ms
2016-11-22 20:29:31,578 _log_update: [1420] (79.9 %) of epoch 9 -- lr = 2, cost = 4.40, duration = 7.3 ms
2016-11-22 20:29:46,297 _log_update: [1620] (91.1 %) of epoch 9 -- lr = 2, cost = 4.49, duration = 7.3 ms
2016-11-22 20:29:59,732 _validate: [1772] First validation sample, perplexity 133.21.
2016-11-22 20:30:06,709 _validate: [1775] Center of validation, perplexity 133.61.
2016-11-22 20:30:13,687 _validate: [1778] Last validation sample, perplexity 133.66.
2016-11-22 20:30:13,687 _log_validation: [1778] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 137.1 [132.8] 133.5
2016-11-22 20:30:13,687 set_state: layers/output_layer/input/b <- array(101,)
2016-11-22 20:30:13,688 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2016-11-22 20:30:13,691 set_state: layers/output_layer/level1/W <- array(101, 256, 100)
2016-11-22 20:30:13,692 set_state: layers/projection_layer/W <- array(10001, 100)
2016-11-22 20:30:13,693 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2016-11-22 20:30:13,693 set_state: layers/output_layer/level1/b <- array(101, 100)
2016-11-22 20:30:13,693 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2016-11-22 20:30:13,694 set_state: layers/output_layer/input/W <- array(256, 101)
2016-11-22 20:30:13,695 _reset_state: [1775] (99.83 %) of epoch 8
2016-11-22 20:30:13,695 _log_validation: [1775] Validation set cost history: 259.5 189.1 163.4 149.1 142.2 138.3 137.1 [132.8]
2016-11-22 20:30:13,695 set_state: Restored iterator to line 42005 of 42068.
2016-11-22 20:30:13,696 set_state: layers/output_layer/level1/b_gradient <- array(101, 100)
2016-11-22 20:30:13,696 set_state: layers/output_layer/input/b_gradient <- array(101,)
2016-11-22 20:30:13,697 set_state: layers/hidden_layer/step_input/W_gradient <- array(256, 1024)
2016-11-22 20:30:13,698 set_state: layers/projection_layer/W_gradient <- array(10001, 100)
2016-11-22 20:30:13,699 set_state: layers/hidden_layer/layer_input/W_gradient <- array(100, 1024)
2016-11-22 20:30:13,699 set_state: layers/hidden_layer/layer_input/b_gradient <- array(1024,)
2016-11-22 20:30:13,702 set_state: layers/output_layer/level1/W_gradient <- array(101, 256, 100)
2016-11-22 20:30:13,703 set_state: layers/output_layer/input/W_gradient <- array(256, 101)
Model performance stopped improving. Decreasing learning rate from 2.5 to 1.25 and resetting state to 100 % of epoch 8.
Finished training epoch 8 in 0 hours 2.5 minutes. Best validation perplexity 132.79.
Training finished in 0 hours 27.7 minutes.
2016-11-22 20:30:13,704 set_state: layers/output_layer/input/b <- array(101,)
2016-11-22 20:30:13,704 set_state: layers/hidden_layer/layer_input/b <- array(1024,)
2016-11-22 20:30:13,707 set_state: layers/output_layer/level1/W <- array(101, 256, 100)
2016-11-22 20:30:13,708 set_state: layers/projection_layer/W <- array(10001, 100)
2016-11-22 20:30:13,709 set_state: layers/hidden_layer/layer_input/W <- array(100, 1024)
2016-11-22 20:30:13,709 set_state: layers/output_layer/level1/b <- array(101, 100)
2016-11-22 20:30:13,710 set_state: layers/hidden_layer/step_input/W <- array(256, 1024)
2016-11-22 20:30:13,710 set_state: layers/output_layer/input/W <- array(256, 101)
Best validation set perplexity: 133.219924845
train finished.
Computing evaluation set perplexity.
Reading vocabulary from network state.
Number of words in vocabulary: 10001
Number of word classes: 10001
Building neural network.
Restoring neural network state.
Building text scorer.
Scoring text.
Number of sentences: 3761
Number of words: 86191
Number of predicted probabilities: 82430
Cross entropy (base e): 4.855034887111563
Perplexity: 128.38517012434465
