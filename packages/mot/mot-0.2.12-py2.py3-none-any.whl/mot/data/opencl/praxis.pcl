#ifndef PRAXIS_CL
#define PRAXIS_CL

/**
 * Creator = Robbert Harms
 * Date = 2015-11-12
 * License = LGPL v3
 * Maintainer = Robbert Harms
 * Email = robbert.harms@maastrichtuniversity.nl
 */

/*   This algorithm was copied from the NLOpt library.

praxis gradient-free local optimization via the "principal-axis method",
downloaded from Netlib:

	http://netlib.org/opt/praxis

The original Fortran code was written by Richard Brent and made
available by the Stanford Linear Accelerator Center, dated 3/1/73.
Since this code contains no copyright statements and is dated prior to
1977, under US copyright law it is in the public domain (not copyrighted).

Converted to C via f2c and cleaned up by Steven G. Johnson
(stevenj@alum.mit.edu).  C version is licensed under the MIT license
(which is in the same spirit as public domain, but disclaims warranty
and is clearer legally).

Original fortran comment:

                    LAST MODIFIED 3/1/73
            Modified August 2007 by S. G. Johnson:
              after conversion to C via f2c and some manual cleanup,

     praxis returns the minimum of the function f(n,x) of n variables
     using the principal axis method.  the gradient of the function is
     not required.

     for a description of the algorithm, see chapter seven of
     "algorithms for finding zeros and extrema of functions without
     calculating derivatives" by Richard P Brent.

     the parameters are:

     x        is an array containing on entry a guess of the point of
              minimum, on return the estimated point of minimum.

     f(n,x)   is the function to be minimized.  f should be a real*8
              function declared external in the calling program.

     the approximating quadratic form is
              q(x') = f(n,x) + (1/2) * (x'-x)-transpose * a * (x'-x)
     where x is the best estimate of the minimum and a is
              inverse(v-transpose) * d * inverse(v)
     (v(*,*) is the matrix of search directions; d(*) is the array
     of second differences).  if f has continuous second derivatives
     near x0, a will tend to the hessian of f at x0 as x approaches x0.
 */

#define PATIENCE %(PATIENCE)r /* Used to set the maximum number of function evaluations
                                to patience*(number_of_parameters+1). */
#define TOLERANCE %(TOLERANCE)r  /** praxis attempts to return praxis=f(x) such that if x0 is the true local minimum
                                  near x, then norm(x-x0) < t0 + squareroot(machep)*norm(x).*/
#define MACH_EPS     30*MOT_EPSILON  /** the precision we break at*/
#define MAX_STEP_SIZE %(MAX_STEP_SIZE)r  /** Originally parameter H0. It is the maximum step size and
                                  should be set to about the max. distance from the initial guess to the minimum.
                                  If set too small or too large, the initial rate of convergence may be slow.*/
#define MAX_FUNC_EVALS (PATIENCE * (%(NMR_PARAMS)s+1)) /** Maximum function evaluations */
#define ILL_CONDITIONED %(ILL_CONDITIONED)r /* heuristic: the problem is known to be ill-conditioned,
                                               set ILL_CONDITIONED to 1 (true). otherwise set ILL_CONDITIONED
                                               0 (false). */
#define SCBD %(SCBD)r         /* heuristic: if the axes may be badly scaled (which is to be avoided if possible),
                                 then set SCBD=10.  otherwise set SCBD=1. */
#define KTM %(KTM)r           /* heuristic: KTM is the number of iterations without improvement before
                                 the algorithm terminates. KTM=4 is very cautious; usually KTM=1 is satisfactory. */

/** some definitions of small numbers */
#define PRAXIS_SMALL (MACH_EPS * MACH_EPS)
#define PRAXIS_VSMALL (PRAXIS_SMALL * PRAXIS_SMALL)
#define PRAXIS_LARGE (1. / PRAXIS_SMALL)
#define PRAXIS_VLARGE (1. / PRAXIS_VSMALL)
#define PRAXIS_M2 (sqrt(MACH_EPS))
#define PRAXIS_M4 (sqrt(PRAXIS_M2))


typedef enum {
     RETURN_CODE_FAILURE = -1, /* generic failure code */
     RETURN_CODE_ROUNDOFF_LIMITED = -2,
     RETURN_CODE_SUCCESS = 1, /* generic success code */
     RETURN_CODE_STOPVAL_REACHED = 2,
     RETURN_CODE_FTOL_REACHED = 3,
     RETURN_CODE_XTOL_REACHED = 4,
     RETURN_CODE_MAXEVAL_REACHED = 5,
} return_code;


struct global_s {
    mot_float_type fx, ldt, dmin__;
    int nf, nl;
};

struct q_s {
    mot_float_type *v; /* size n x n */
    mot_float_type *q0, *q1, *t_flin; /* size n */
    mot_float_type qa, qb, qc, qd0, qd1, qf1;
    mot_float_type fbest, *xbest; /* size n */
};

/* Table of constant values */
/* compute x^n, n >= 0 */
int pow_ii(int x, int n){
    int p = 1;
    while (n > 0) {
        if (n & 1) {
            n--;
            p *= x;
        }
        else {
            n >>= 1;
            x *= x;
        }
    }
    return p;
}

return_code praxis_(int n, mot_float_type *x, const void * const data, mot_float_type *minf, void* rand_settings);

int praxis(mot_float_type* model_parameters, const void* const data, void* rand_settings){
    mot_float_type minf = 0;
    praxis_(%(NMR_PARAMS)r, model_parameters, data, &minf, rand_settings);
}

int relstop(mot_float_type vold, mot_float_type vnew){
     if (isinf(vold)){
        return 0;
     }
     return(fabs(vnew - vold) < 0
        || fabs(vnew - vold) < 0 * (fabs(vnew) + fabs(vold)) * 0.5
	    || (0 > 0 && vnew == vold)); /* catch vnew == vold == 0 */
}

int stopping_test_f(mot_float_type f, mot_float_type oldf){
     return (f <= 0 || relstop(f, oldf));
}

int stopping_test_x(const mot_float_type *x, const mot_float_type *oldx){
     for(int i = 0; i < %(NMR_PARAMS)r; ++i){
        if (!relstop(oldx[i], x[i])){
            return 0;
        }
     }
     return 1;
}

void minfit_(int m, int n, mot_float_type tol, mot_float_type *ab, mot_float_type *q, mot_float_type *ework);
return_code min_(int n, int j, int nits, mot_float_type *d2, mot_float_type *x1, mot_float_type *f1, int fk, const void * const data, mot_float_type *x, mot_float_type *t_old, mot_float_type *h__, struct global_s *global_1, struct q_s *q_1);
mot_float_type flin_(int n, int j, mot_float_type *l, const void * const data, mot_float_type *x, int *nf, struct q_s *q_1, return_code *ret);
void sort_(int m, int n, mot_float_type *d__, mot_float_type *v);
void quad_(int n, const void * const data, mot_float_type *x, mot_float_type *t_old, mot_float_type *h__, struct global_s *global_1, struct q_s *q_1);

return_code praxis_(int n, mot_float_type *x, const void * const data, mot_float_type *minf, void* rand_settings)
{
    return_code ret = RETURN_CODE_SUCCESS;

    /* Global */
    struct global_s global_1;
    struct q_s q_1;

    /* Local variables */
    mot_float_type *d__, *y, *z__, *e_minfit, *prev_xbest; /* size n */
    mot_float_type prev_fbest;
    mot_float_type h__;
    int i__, j, k, kl, ii, kt, illc;
    mot_float_type s, t_old, f1;
    mot_float_type t2_old, df, dn;
    mot_float_type sf;
    mot_float_type sl;
    mot_float_type dni, lds;
    mot_float_type ldfac, value;
    mot_float_type work[(%(NMR_PARAMS)r * %(NMR_PARAMS)r + %(NMR_PARAMS)r * 9)];

    --x;

    q_1.v = work;
    q_1.q0 = q_1.v + n*n;
    q_1.q1 = q_1.q0 + n;
    q_1.t_flin = q_1.q1 + n;
    q_1.xbest = q_1.t_flin + n;
    d__ = q_1.xbest + n;
    y = d__ + n;
    z__ = y + n;
    e_minfit = y + n;
    prev_xbest = e_minfit + n;
    illc = ILL_CONDITIONED;

    ldfac = .01;
    if (illc) {
        ldfac = .1;
    }

    kt = 0;
    global_1.nl = 0;
    global_1.nf = 1;
    prev_fbest = q_1.fbest = global_1.fx = evaluate(&x[1], data);

    for(j = 0; j < n; j++){
		q_1.xbest[j] = (&x[1])[j];
		prev_xbest[j] = (&x[1])[j];
	}

    q_1.qf1 = global_1.fx;

    if (TOLERANCE > 0)
        t_old = PRAXIS_SMALL + TOLERANCE;
    else {
        t_old = 0;
        t_old += PRAXIS_SMALL;
    }

    t2_old = t_old;
    global_1.dmin__ = PRAXIS_SMALL;
    h__ = MAX_STEP_SIZE;

    if (h__ < t_old * 100) {
        h__ = t_old * 100;
    }
    global_1.ldt = h__;

    /* .....the first set of search directions v is the identity matrix..... */
    for (i__ = 1; i__ <= n; ++i__) {
        for (j = 1; j <= n; ++j) {
            q_1.v[i__ + j * n - (n+1)] = 0.;
        }
        q_1.v[i__ + i__ * n - (n+1)] = 1.;
    }

    d__[0] = 0.;
    q_1.qd0 = 0.;
    for (i__ = 1; i__ <= n; ++i__) {
        q_1.q0[i__ - 1] = x[i__];
        q_1.q1[i__ - 1] = x[i__];
    }

    /* .....THE MAIN LOOP STARTS HERE..... */
	while(1){
		sf = d__[0];
		d__[0] = 0.;
		s = 0.;

		/* .....minimize along the first direction v(*,1). */
		/*     fx must be passed to min by value. */
		value = global_1.fx;
		ret = min_(n, 1, 2, d__, &s, &value, 0, data, &x[1], &t_old, &h__, &global_1, &q_1);

		if (ret != RETURN_CODE_SUCCESS){
			*minf = q_1.fbest;

			for(j = 0; j < n; j++){
				(&x[1])[j] = q_1.xbest[j];
			}
			return ret;
		}

		if (s <= 0.){
			for (i__ = 1; i__ <= n; ++i__) {
				q_1.v[i__ - 1] = -q_1.v[i__ - 1];
			}
		}

		if(!(sf > d__[0] * .9 && sf * .9 < d__[0])){
			for (i__ = 2; i__ <= n; ++i__) {
				d__[i__ - 1] = 0.;
			}
		}

		/* .....the inner loop starts here..... */
		for (k = 2; k <= n; ++k) {
			for (i__ = 1; i__ <= n; ++i__) {
				y[i__ - 1] = x[i__];
			}
			sf = global_1.fx;
			if (kt > 0) {
				illc = 1 /* true */;
			}

			while(1){
				kl = k;
				df = 0.;

				/* .....a random step follows (to avoid resolution valleys). */
				/*     praxis assumes that random returns a random number uniformly */
				/*     distributed in (0,1). */
				if(!(! illc)){
					for (i__ = 1; i__ <= n; ++i__) {
						s = (global_1.ldt * .1 + t2_old * pow_ii(10, kt))
							* (rand(rand_settings) - .5);

						z__[i__ - 1] = s;
						for (j = 1; j <= n; ++j) {
							x[j] += s * q_1.v[j + i__ * n - (n+1)];
						}
					}

					global_1.fx = evaluate(&x[1], data);
					++global_1.nf;
				}

				/* .....minimize along the "non-conjugate" directions v(*,k),...,v(*,n) */
				for (i__ = k; i__ <= n; ++i__) {
					sl = global_1.fx;
					s = 0.;
					value = global_1.fx;
					ret = min_(n, i__, 2, &d__[i__ - 1], &s, &value, 0, data, &x[1], &t_old, &h__, &global_1, &q_1);

					if (ret != RETURN_CODE_SUCCESS){
						*minf = q_1.fbest;
						for(j = 0; j < n; j++){
							(&x[1])[j] = q_1.xbest[j];
						}
						return ret;
					}

					if (illc) {
						s = d__[i__ - 1] * ((s + z__[i__ - 1]) * (s + z__[i__ - 1]));
					}
					else{
						s = sl - global_1.fx;
					}

					if (df <= s){
						df = s;
						kl = i__;
					}
				}

				if (illc || df >= fabs(MACH_EPS * 100 * global_1.fx)){
					break; // break out of while(1)
				}

				/* .....if there was not much improvement on the first try, set */
				/*     illc=true and start the inner loop again..... */
				illc = 1 /* true */;
			}

			/* .....minimize along the "conjugate" directions v(*,1),...,v(*,k-1) */
			for (i__ = 1; i__ <= k - 1; ++i__) {
				s = 0.;
				value = global_1.fx;
				ret = min_(n, i__, 2, &d__[i__ - 1], &s, &value, 0, data, &x[1], &t_old, &h__, &global_1, &q_1);

				if (ret != RETURN_CODE_SUCCESS){
					*minf = q_1.fbest;
					for(j = 0; j< n; j++){
						(&x[1])[j] = q_1.xbest[j];
					}
					return ret;
				}
			}

			f1 = global_1.fx;
			global_1.fx = sf;
			lds = 0.;
			for (i__ = 1; i__ <= n; ++i__) {
				sl = x[i__];
				x[i__] = y[i__ - 1];
				sl -= y[i__ - 1];
				y[i__ - 1] = sl;
				lds += sl * sl;
			}

			lds = sqrt(lds);
			if (lds > PRAXIS_SMALL){
				/* .....discard direction v(*,kl). */
				/*     if no random step was taken, v(*,kl) is the "non-conjugate" */
				/*     direction along which the greatest improvement was made..... */
				if ((kl - k) >= 1){
					for (ii = 1; ii <= kl - k; ++ii) {
						i__ = kl - ii;
						for (j = 1; j <= n; ++j) {
							q_1.v[j + (i__ + 1) * n - (n+1)] = q_1.v[j + i__ * n - (n+1)];
						}
						d__[i__] = d__[i__ - 1];
					}
				}

				d__[k - 1] = 0.;
				for (i__ = 1; i__ <= n; ++i__) {
					q_1.v[i__ + k * n - (n+1)] = y[i__ - 1] / lds;
				}

				/* .....minimize along the new "conjugate" direction v(*,k), which is */
				/*     the normalized vector:  (new x) - (0ld x)..... */
				value = f1;
				ret = min_(n, k, 4, &d__[k - 1], &lds, &value, 1, data, &x[1], &t_old, &h__, &global_1, &q_1);

				if (ret != RETURN_CODE_SUCCESS){
					*minf = q_1.fbest;
					for(j = 0; j < n; j++){
						(&x[1])[j] = q_1.xbest[j];
					}
					return ret;
				}

				if (lds <= 0.){
					lds = -lds;
					for (i__ = 1; i__ <= n; ++i__) {
						q_1.v[i__ + k * n - (n+1)] = -q_1.v[i__ + k * n - (n+1)];
					}
				}
			}

			global_1.ldt = ldfac * global_1.ldt;
			if (global_1.ldt < lds) {
				global_1.ldt = lds;
			}

			t2_old = 0.;
			for (i__ = 1; i__ <= n; ++i__) {
				t2_old += (x[i__] * x[i__]);
			}
			t2_old = PRAXIS_M2 * sqrt(t2_old) + t_old;

			/* .....see whether the length of the step taken since starting the */
			/*     inner loop exceeds half the tolerance..... */
			if (global_1.ldt > t2_old * .5f
					&& !stopping_test_f(q_1.fbest, prev_fbest)
					&& !stopping_test_x(q_1.xbest, prev_xbest)) {
				kt = -1;
			}

			++kt;
			if (kt > KTM) {
				if (stopping_test_f(q_1.fbest, prev_fbest)){
					ret = RETURN_CODE_FTOL_REACHED;
				}
				else if (stopping_test_x(q_1.xbest, prev_xbest)){
					ret = RETURN_CODE_XTOL_REACHED;
				}

				*minf = q_1.fbest;
				for(j = 0; j < n; j++){
					(&x[1])[j] = q_1.xbest[j];
				}
				return ret;

			}
			prev_fbest = q_1.fbest;

			for(j = 0; j < n; j++){
				prev_xbest[j] = q_1.xbest[j];
			}
		}

		/* try quadratic extrapolation in case we are in a curved valley. */
		quad_(n, data, &x[1], &t_old, &h__, &global_1, &q_1);
		dn = 0.;
		for (i__ = 1; i__ <= n; ++i__) {
			d__[i__ - 1] = 1. / sqrt(d__[i__ - 1]);
			if (dn < d__[i__ - 1]) {
				dn = d__[i__ - 1];
			}
		}

		for (j = 1; j <= n; ++j) {
			s = d__[j - 1] / dn;
			for (i__ = 1; i__ <= n; ++i__) {
				q_1.v[i__ + j * n - (n+1)] = s * q_1.v[i__ + j * n - (n+1)];
			}
		}

		/* .....scale the axes to try to reduce the condition number..... */
		if (SCBD > 1.){
			s = PRAXIS_VLARGE;
			for (i__ = 1; i__ <= n; ++i__) {
				sl = 0.;

				for (j = 1; j <= n; ++j) {
					sl += q_1.v[i__ + j * n - (n+1)] * q_1.v[i__ + j * n - (n+1)];
				}
				z__[i__ - 1] = sqrt(sl);

				if (z__[i__ - 1] < PRAXIS_M4) {
					z__[i__ - 1] = PRAXIS_M4;
				}

				if (s > z__[i__ - 1]) {
					s = z__[i__ - 1];
				}
			}

			for (i__ = 1; i__ <= n; ++i__) {
            	sl = s / z__[i__ - 1];
				z__[i__ - 1] = 1. / sl;

				if (z__[i__ - 1] > SCBD){
					sl = 1. / SCBD;
					z__[i__ - 1] = SCBD;
				}

				for (j = 1; j <= n; ++j) {
					q_1.v[i__ + j * n - (n+1)] = sl * q_1.v[i__ + j * n - (n+1)];
				}
			}
		}

		/* .....calculate a new set of orthogonal directions before repeating */
		/*     the main loop. */
		/*     first transpose v for minfit: */
		for (i__ = 2; i__ <= n; ++i__){
			for (j = 1; j <= i__ - 1; ++j) {
				s = q_1.v[i__ + j * n - (n+1)];
				q_1.v[i__ + j * n - (n+1)] = q_1.v[j + i__ * n - (n+1)];
				q_1.v[j + i__ * n - (n+1)] = s;
			}
		}

		/* .....call minfit to find the singular value decomposition of v. */
		/*     this gives the principal values and principal directions of the */
		/*     approximating quadratic form without squaring the condition */
		/*     number..... */
		minfit_(n, n, PRAXIS_VSMALL, q_1.v, d__, e_minfit);


		/* .....unscale the axes..... */
		if (SCBD > 1.){
			for (i__ = 1; i__ <= n; ++i__) {
				s = z__[i__ - 1];
				for (j = 1; j <= n; ++j) {
					q_1.v[i__ + j * n - (n+1)] = s * q_1.v[i__ + j * n - (n+1)];
				}
			}
			for (i__ = 1; i__ <= n; ++i__) {
				s = 0.;
				for (j = 1; j <= n; ++j) {
					s += (q_1.v[j + i__ * n - (n+1)] * q_1.v[j + i__ * n - (n+1)]);
				}

				s = sqrt(s);
				d__[i__ - 1] = s * d__[i__ - 1];
				s = 1 / s;
				for (j = 1; j <= n; ++j) {
					q_1.v[j + i__ * n - (n+1)] = s * q_1.v[j + i__ * n - (n+1)];
				}
			}
		}

		for (i__ = 1; i__ <= n; ++i__) {
			dni = dn * d__[i__ - 1];
			if (dni > PRAXIS_LARGE) {
				d__[i__ - 1] = PRAXIS_VSMALL;
			}
			else if (dni < PRAXIS_SMALL) {
				d__[i__ - 1] = PRAXIS_VLARGE;
			}
			else{
				d__[i__ - 1] = 1 / (dni * dni);
			}
		}

		/* .....sort the eigenvalues and eigenvectors..... */

		sort_(n, n, d__, q_1.v);
		global_1.dmin__ = d__[n - 1];
		if (global_1.dmin__ < PRAXIS_SMALL) {
			global_1.dmin__ = PRAXIS_SMALL;
		}

		illc = 0 /* false */;
		if (PRAXIS_M2 * d__[0] > global_1.dmin__) {
			illc = 1 /* true */;
		}
	}
} /* praxis_ */

/* ...an improved version of minfit (see golub and reinsch, 1969) */
/*   restricted to m=n,p=0. */
/*   the singular values of the array ab are returned in q and ab is */
/*   overwritten with the orthogonal matrix v such that u.diag(q) = ab.v, */
/*   where u is another orthogonal matrix. */
/* ...householder's reduction to bidiagonal form... */
void minfit_(const int m, const int n, mot_float_type tol, mot_float_type *ab, mot_float_type *q, mot_float_type *ework){

    mot_float_type *e; /* size n */
    mot_float_type c__, f, g, h__;
    int i__, j, k, l, ii, kk, kt;
    mot_float_type s, x, y, z__;
    mot_float_type eps, temp;

    e = ework;

    /* Parameter adjustments */
    --q;
    ab -= 1 + m;

    /* Function Body */
    if (n == 1) {
		q[1] = ab[m + 1];
		ab[m + 1] = 1.;
    }
    else{
		eps = MACH_EPS;
		g = 0.;
		x = 0.;
		for (i__ = 1; i__ <= n; ++i__) {
			e[i__ - 1] = g;
			s = 0.;
			l = i__ + 1;

			for (j = i__; j <= n; ++j) {
				s += (ab[j + i__ * m] * ab[j + i__ * m]);
			}
			g = 0.;

			if (s >= tol){
				f = ab[i__ + i__ * m];
				g = sqrt(s);

				if (f >= 0.) {
					g = -g;
				}

				h__ = f * g - s;
				ab[i__ + i__ * m] = f - g;

				if (l <= n){
					for (j = l; j <= n; ++j) {
						f = 0.;

						for (k = i__; k <= n; ++k) {
							f += ab[k + i__ * m] * ab[k + j * m];
						}

						f /= h__;
						for (k = i__; k <= n; ++k) {
							ab[k + j * m] += f * ab[k + i__ * m];
						}
					}
				}
			}

			q[i__] = g;
			s = 0.;
			if (i__ != n){
				for (j = l; j <= n; ++j) {
					s += ab[i__ + j * m] * ab[i__ + j * m];
				}
			}

			g = 0.;
			if (s >= tol){
				if (i__ != n){
					f = ab[i__ + (i__ + 1) * m];
				}

				g = sqrt(s);

				if (f >= 0.) {
					g = -g;
				}

				h__ = f * g - s;

				if (i__ != n){
					ab[i__ + (i__ + 1) * m] = f - g;
					for (j = l; j <= n; ++j) {
						e[j - 1] = ab[i__ + j * m] / h__;
					}

					for (j = l; j <= n; ++j) {
						s = 0.;

						for (k = l; k <= n; ++k) {
							s += ab[j + k * m] * ab[i__ + k * m];
						}

						for (k = l; k <= n; ++k) {
							ab[j + k * m] += s * e[k - 1];
						}
					}
				}
			}

			y = (fabs(q[i__]) + fabs(e[i__ - 1]));
			if (y > x) {
				x = y;
			}
		}

		/* ...accumulation of right-hand transformations... */
		ab[n + n * m] = 1.;
		g = e[n - 1];
		l = n;
		for (ii = 2; ii <= n; ++ii) {
			i__ = n - ii + 1;

			if (g != 0.) {
				h__ = ab[i__ + (i__ + 1) * m] * g;
				for (j = l; j <= n; ++j) {
					ab[j + i__ * m] = ab[i__ + j * m] / h__;
				}
				for (j = l; j <= n; ++j) {
					s = 0.;
					for (k = l; k <= n; ++k) {
						s += ab[i__ + k * m] * ab[k + j * m];
					}
					for (k = l; k <= n; ++k) {
						ab[k + j * m] += s * ab[k + i__ * m];
					}
				}
			}

			for (j = l; j <= n; ++j) {
				ab[i__ + j * m] = 0.;
				ab[j + i__ * m] = 0.;
			}
			ab[i__ + i__ * m] = 1.;
			g = e[i__ - 1];
			l = i__;
		}

		/* ...diagonalization of the bidiagonal form... */
		eps *= x;
		for (kk = 1; kk <= n; ++kk) {
			k = n - kk + 1;
			kt = 0;

			while(1){
				++kt;
				if(kt > 30){
					e[k - 1] = 0.;
				}
				for (ii = 1; ii <= k; ++ii) {
					l = k - ii + 1;
					if (fabs(e[l - 1]) <= eps) {
						break;
					}
					else if (l == 1) {
					}
					else if (fabs(q[l - 1]) <= eps) {
						/* ...cancellation of e(l) if l>1... */
						c__ = 0.;
						s = 1.;
						for (i__ = l; i__ <= k; ++i__){
							f = s * e[i__ - 1];
							e[i__ - 1] = c__ * e[i__ - 1];

							if (fabs(f) <= eps) {
								break;
							}
							g = q[i__];

							/* ...Q(I) = H = DSQRT(G*G + F*F)... */
							if (fabs(f) < fabs(g)) {
								/* Computing 2nd power */
								h__ = fabs(g) * sqrt(((f / g) * (f / g)) + 1);
							}
							else if (f != 0.) {
								/* Computing 2nd power */
								h__ = fabs(f) * sqrt(((g / f) * (g / f)) + 1);
							}
							else {
								h__ = 0.;
							}

							q[i__] = h__;
							if(!(h__ != 0.)){
								g = 1.;
								h__ = 1.;
							}

							c__ = g / h__;
							s = -f / h__;
						}

						break;
					}
				}

				/* ...test for convergence... */
				z__ = q[k];
				if (l == k) {
					/* ...convergence:  q(k) is made non-negative... */
					if (z__ < 0.){
						q[k] = -z__;
						for (j = 1; j <= n; ++j) {
							ab[j + k * m] = -ab[j + k * m];
						}
					}
					break;
				}
				else{
					/* ...shift from bottom 2*2 minor... */
					x = q[l];
					y = q[k - 1];
					g = e[k - 2];
					h__ = e[k - 1];
					f = ((y - z__) * (y + z__) + (g - h__) * (g + h__)) / (h__ * 2 * y);
					g = sqrt(f * f + 1.);

					temp = f - g;
					if (f >= 0.) {
						temp = f + g;
					}

					f = ((x - z__) * (x + z__) + h__ * (y / temp - h__)) / x;

					/* ...next qr transformation... */
					c__ = 1.;
					s = 1.;

					if ((l + 1) <= k){
						for (i__ = l + 1; i__ <= n; ++i__) {
							g = e[i__ - 1];
							y = q[i__];
							h__ = s * g;
							g *= c__;

							if (fabs(f) < fabs(h__)) {
								/* Computing 2nd power */
								z__ = fabs(h__) * sqrt(((f / h__) * (f / h__)) + 1);
							}
							else if (f != 0.) {
								/* Computing 2nd power */
								z__ = fabs(f) * sqrt(((h__ / f) * (h__ / f)) + 1);
							}
							else {
								z__ = 0.;
							}

							e[i__ - 2] = z__;
							if (!(z__ != 0.)){
								f = 1.;
								z__ = 1.;
							}

							c__ = f / z__;
							s = h__ / z__;
							f = x * c__ + g * s;
							g = -x * s + g * c__;
							h__ = y * s;
							y *= c__;

							for (j = 1; j <= n; ++j) {
								x = ab[j + (i__ - 1) * m];
								z__ = ab[j + i__ * m];
								ab[j + (i__ - 1) * m] = x * c__ + z__ * s;
								ab[j + i__ * m] = -x * s + z__ * c__;
							}

							if (fabs(f) < fabs(h__)) {
								/* Computing 2nd power */
								z__ = fabs(h__) * sqrt(((f / h__)*(f / h__)) + 1);
							}
							else if (f != 0.) {
								/* Computing 2nd power */
								z__ = fabs(f) * sqrt(((h__ / f)*(h__ / f)) + 1);
							}
							else {
								z__ = 0.;
							}

							q[i__ - 1] = z__;
							if (!(z__ != 0.)){
								f = 1.;
								z__ = 1.;
							}

							c__ = f / z__;
							s = h__ / z__;
							f = c__ * g + s * y;
							x = -s * g + c__ * y;
						}
					}

					e[l - 1] = 0.;
					e[k - 1] = f;
					q[k] = x;
				}
			}
		}
	}
} /* minfit_ */

/* ...the subroutine min minimizes f from x in the direction v(*,j) unless */
/*   j is less than 1, when a quadratic search is made in the plane */
/*   defined by q0,q1,x. */
/*   d2 is either zero or an approximation to half f". */
/*   on entry, x1 is an estimate of the distance from x to the minimum */
/*   along v(*,j) (or, if j=0, a curve).  on return, x1 is the distance */
/*   found. */
/*   if fk=.true., then f1 is flin(x1).  otherwise x1 and f1 are ignored */
/*   on entry unless final fx is greater than f1. */
/*   nits controls the number of times an attempt will be made to halve */
/*   the interval. */
return_code min_(const int n, const int j, int nits, mot_float_type * d2,
                         mot_float_type *x1, mot_float_type *f1, int fk, const void * const data, mot_float_type * x,
                         mot_float_type *t_old, mot_float_type *h__, struct global_s *global_1, struct q_s *q_1){
    int i__, k;
    mot_float_type f0, x2, fm;
    int dz;
    mot_float_type xm, sf1, sx1;
    mot_float_type temp;
    return_code ret = RETURN_CODE_SUCCESS;

	/* this variable is first used as 's' for the step size determination.
	 * next, it is used as d1 to hold the value of the first derivative.
	 * this is purely to save a double/float */
    mot_float_type s_and_d1;

    /* this variable is first used as 't2', second as f2.
     * this is purely to save a double/float */
    mot_float_type t2_and_f2;

    --x;

    sf1 = *f1;
    sx1 = *x1;
    k = 0;
    xm = 0.;
    fm = global_1->fx;
    f0 = global_1->fx;
    dz = *d2 < MACH_EPS;

    /* ...find the step size... */
    /* using s_and_d1 and s here */
    s_and_d1 = 0.;
    for (i__ = 1; i__ <= n; ++i__) {
        s_and_d1 += (x[i__] * x[i__]);
    }

    s_and_d1 = sqrt(s_and_d1);

    temp = *d2;
    if (dz) {
        temp = global_1->dmin__;
    }

    /* using t2_and_f2 as t2 */
    t2_and_f2 = PRAXIS_M4 * sqrt(fabs(global_1->fx) / temp + s_and_d1 * global_1->ldt) + PRAXIS_M2 * global_1->ldt;
    s_and_d1 = PRAXIS_M4 * s_and_d1 + *t_old;

    if (dz && t2_and_f2 > s_and_d1) {
        t2_and_f2 = s_and_d1;
    }
    t2_and_f2 = t2_and_f2 > PRAXIS_SMALL ? t2_and_f2 : PRAXIS_SMALL;

	/* end of using s_and_d1 as s */

    /* Computing MIN */
    t2_and_f2 = t2_and_f2 < (*h__ * .01) ? t2_and_f2 : (*h__ * .01);
    if (! (fk) || *f1 > fm) {
    }
    else{
		xm = *x1;
		fm = *f1;
	}
    if (fk && fabs(*x1) >= t2_and_f2) {
    }
    else{
		temp = 1.;
		if (*x1 < 0.) {
			temp = -1.;
		}
		*x1 = temp * t2_and_f2;
		*f1 = flin_(n, j, x1, data, &x[1], &global_1->nf, q_1, &ret);
		if (ret != RETURN_CODE_SUCCESS) return ret;
	}
    if (*f1 > fm) {
    }
    else{
		xm = *x1;
		fm = *f1;
	}

    /* end of using t2_and_f2 as t2 */
    /* start using t2_and_f2 as f2 in the while loop */

	while(1){
		if(!(! dz)){
			/* ...evaluate flin at another point and estimate the second derivative... */
			x2 = -(*x1);
			if (f0 >= *f1) {
				x2 = *x1 * 2.;
			}
			t2_and_f2 = flin_(n, j, &x2, data, &x[1], &global_1->nf, q_1, &ret);
			if (ret != RETURN_CODE_SUCCESS) return ret;
			if (t2_and_f2 > fm) {
			}
			else{
				xm = x2;
				fm = t2_and_f2;
			}
			*d2 = (x2 * (*f1 - f0) - *x1 * (t2_and_f2 - f0)) / (*x1 * x2 * (*x1 - x2));
		}

		/* ...estimate the first derivative at 0... */
		/* using s_and_d1 as d1 here */
		s_and_d1 = (*f1 - f0) / *x1 - *x1 **d2;
		dz = 1 /* true */;

		/* ...predict the minimum... */
		if (*d2 > PRAXIS_SMALL) {
			x2 = s_and_d1 * -.5 / *d2;
		}
		else{
			x2 = *h__;
			if (s_and_d1 >= 0.) {
				x2 = -x2;
			}
		}
		if(fabs(x2) > *h__){
			if (x2 <= 0.) {
				x2 = -(*h__);
			} else {
				x2 = *h__;
			}
		}

		/* ...evaluate f at the predicted minimum... */
		while(1){
			t2_and_f2 = flin_(n, j, &x2, data, &x[1], &global_1->nf, q_1, &ret);
			if (ret != RETURN_CODE_SUCCESS){
			    return ret;
			}

			if (k >= nits || t2_and_f2 <= f0) {
				break;
			}

			/* ...no success, so try again... */
			++k;
			if (f0 < *f1 && *x1 * x2 > 0.) {
				break;
			}
			x2 *= .5;
		}

		if (k >= nits || t2_and_f2 <= f0) {
			break;
		}
	}

    /* ...increment the one-dimensional search counter... */
    ++global_1->nl;
    if (t2_and_f2 <= fm) {
        fm = t2_and_f2;
    }
    else{
		x2 = xm;
	}

    /* ...get a new estimate of the second derivative... */
    if(fabs(x2 * (x2 - *x1)) <= PRAXIS_SMALL){
        if (k > 0) {
			*d2 = 0.;
		}
    }
    else{
		*d2 = (x2 * (*f1 - f0) - *x1 * (fm - f0)) / (*x1 * x2 * (*x1 - x2));
	}

    if (*d2 <= PRAXIS_SMALL) {
        *d2 = PRAXIS_SMALL;
    }

    *x1 = x2;
    global_1->fx = fm;

    if(sf1 < global_1->fx){
		global_1->fx = sf1;
		*x1 = sx1;
	}

    /* ...update x for linear but not parabolic search... */
    if (j == 0) {
        return RETURN_CODE_SUCCESS;
    }

    for (i__ = 1; i__ <= n; ++i__) {
        x[i__] += *x1 * q_1->v[i__ + j * n - (n+1)];
    }

    return RETURN_CODE_SUCCESS;
} /* min_ */

/* ...flin is the function of one real variable l that is minimized by the subroutine min... */
mot_float_type flin_(const int n, const int j, mot_float_type *l, const void * const data, mot_float_type *x, int *nf, struct q_s *q_1, return_code *ret){

    mot_float_type ret_val;
    int i__;
    mot_float_type *t; /* size n */

    t = q_1->t_flin;
    --x;

    if(j == 0){
        /* ...the search is along a parabolic space curve... */
		q_1->qa = *l * (*l - q_1->qd1) / (q_1->qd0 * (q_1->qd0 + q_1->qd1));
		q_1->qb = (*l + q_1->qd0) * (q_1->qd1 - *l) / (q_1->qd0 * q_1->qd1);
		q_1->qc = *l * (*l + q_1->qd0) / (q_1->qd1 * (q_1->qd0 + q_1->qd1));
		for (i__ = 1; i__ <= n; ++i__) {
			/* L3: */
			t[i__ - 1] = q_1->qa * q_1->q0[i__ - 1] + q_1->qb * x[i__] + q_1->qc *
						 q_1->q1[i__ - 1];
		}
    }
    else{
		/* ...the search is linear... */
		for (i__ = 1; i__ <= n; ++i__) {
			t[i__ - 1] = x[i__] + *l * q_1->v[i__ + j * n - (n+1)];
		}
	}
    /* ...the function evaluation counter nf is incremented... */
    ++(*nf);
    ret_val = evaluate(t, data);
    if (ret_val < q_1->fbest) {
        q_1->fbest = ret_val;

        for(i__ = 0; i__ < n; i__++){
			q_1->xbest[i__] = t[i__];
		}
    }

    if((*nf) > MAX_FUNC_EVALS){
		*ret = RETURN_CODE_MAXEVAL_REACHED;
	}
    return ret_val;
} /* flin_ */

/* ...sorts the elements of d(n) into descending order and moves the
	corresponding columns of v(n,n).
    m is the row dimension of v as declared in the calling program.
 */
void sort_(const int m, const int n, mot_float_type *d__, mot_float_type *v){

    /* Local variables */
    int i__, j, k;
    mot_float_type s;

    /* parameter adjustments */
    v -= 1 + m;
    --d__;

    if (n == 1) {
        return;
    }

    for (i__ = 1; i__ <= n - 1; ++i__) {
        k = i__;
        s = d__[i__];

        for (j = i__ + 1; j <= n; ++j) {
            if (d__[j] > s) {
            	k = j;
				s = d__[j];
			}
        }

        if (k > i__){
			d__[k] = d__[i__];
			d__[i__] = s;

			for (j = 1; j <= n; ++j) {
				s = v[j + i__ * m];
				v[j + i__ * m] = v[j + k * m];
				v[j + k * m] = s;
			}
		}
    }
} /* sort_ */

/* ...quad looks for the minimum of f along a curve defined by q0,q1,x... */
void quad_(const int n, const void * const data, mot_float_type *x, mot_float_type *t_old, mot_float_type *h__, struct global_s *global_1, struct q_s *q_1){

    /* Local variables */
    int i__;
    mot_float_type l, s;

    /* Parameter adjustments */
    --x;

    s = global_1->fx;
    global_1->fx = q_1->qf1;
    q_1->qf1 = s;
    q_1->qd1 = 0.;
    for (i__ = 1; i__ <= n; ++i__) {
        s = x[i__];
        l = q_1->q1[i__ - 1];
        x[i__] = l;
        q_1->q1[i__ - 1] = s;
        q_1->qd1 += ((s - l)*(s - l));
    }

    q_1->qd1 = sqrt(q_1->qd1);
    l = q_1->qd1;
    s = 0.;

    if (q_1->qd0 <= 0. || q_1->qd1 <= 0. || global_1->nl < n * 3 * n) {
        global_1->fx = q_1->qf1;
		q_1->qa = 0.;
		q_1->qb = q_1->qa;
		q_1->qc = 1.;
    }
    else{
		min_(n, 0, 2, &s, &l, &(q_1->qf1), 1, data, &x[1], t_old, h__, global_1, q_1);
		q_1->qa = l * (l - q_1->qd1) / (q_1->qd0 * (q_1->qd0 + q_1->qd1));
		q_1->qb = (l + q_1->qd0) * (q_1->qd1 - l) / (q_1->qd0 * q_1->qd1);
		q_1->qc = l * (l + q_1->qd0) / (q_1->qd1 * (q_1->qd0 + q_1->qd1));
	}

    q_1->qd0 = q_1->qd1;
    for (i__ = 1; i__ <= n; ++i__) {
        s = q_1->q0[i__ - 1];
        q_1->q0[i__ - 1] = x[i__];
        x[i__] = q_1->qa * s + q_1->qb * x[i__] + q_1->qc * q_1->q1[i__ - 1];
    }
} /* quad_ */


#endif // PRAXIS_CL
